{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(row):\n",
    "    # transform the large amount of data in row to a much smaller representative subset\n",
    "\n",
    "    # extract important data from row\n",
    "    scan_1080 = row.iloc[0:1080]\n",
    "    local_goal = row.iloc[1084:1088]\n",
    "    robot_pose = row.iloc[1088:1092]\n",
    "    cmd = row.iloc[1092:1094]\n",
    "\n",
    "    # reduce scan data\n",
    "    # 1) bin data using averages from 1080 to 135 -> reduce by factor of 8\n",
    "    # 2) bin data using min from 135 to 9 -> reduce by factor of 15\n",
    "    scan = []  # initalize transformed scan array\n",
    "    for i in range(9):  # there wil be 9 values in scan array\n",
    "        bin = []  # initalize the bin which represents a 30 degree slice of scan\n",
    "        for j in range(15):  # there will be 15 values in bin array\n",
    "            bin.append(np.average(scan_1080[8*j+120*i:8*j+120*i+8]))  # take the average value over 8 sequential scan data points and add it to bin\n",
    "        scan.append(min(bin))  # add the smallest bin value to scan array\n",
    "\n",
    "    # compute difference in local goal and pose\n",
    "    delta = list(np.array(local_goal) - np.array(robot_pose))\n",
    "\n",
    "    new_row = scan + delta + list(np.array(cmd))\n",
    "\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_filenames( path_to_dir, suffix=\".csv\" ):\n",
    "    filenames = os.listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_old = 'Training/corridor_CSV/'\n",
    "filenames = find_csv_filenames(path_old)\n",
    "\n",
    "path_new = 'Training_Clean/corridor_CSV/'\n",
    "path_new = os.path.join(os.getcwd(), path_new)\n",
    "if not os.path.exists(path_new):\n",
    "   os.makedirs(path_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1\n",
      "Processing 1\n"
     ]
    }
   ],
   "source": [
    "# transform all csvs in the path_old directory and put them in the path_new directory\n",
    "for f, name in enumerate(filenames):\n",
    "    print(\"Reading {0}\".format(f+1))\n",
    "    name = os.path.splitext(name)[0]\n",
    "    df_old = pd.read_csv(path_old + name + '.csv', header=None)\n",
    "    df_new = pd.DataFrame(columns = [\"-135:-105\", \"-105:-75\", \"-75:-45\", \"-45:-15\", \"-15:+15\", \"15:45\", \"45:75\", \"75:105\", \"105:135\", \"dx\", \"dy\", \"dqk\", \"dqr\", \"v\", \"w\"])\n",
    "    print(\"Processing {0}\".format(f+1))\n",
    "    \n",
    "    for index, row in df_old.iterrows():\n",
    "        df_new.loc[len(df_new)] = transform(row)\n",
    "    df_new.to_csv(path_new + name + '_clean.csv', index=False)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e36490298f94e073f2db7ad1d852225e2e107f56e2fbb8834d2bd91d06aa6a3a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ML_1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
